# -*- coding: utf-8 -*-
"""Forecasting Corona Outbreak_v3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zT9EOrEOrSmcrFA6UNnWUXfoWtLES2Gb

![<AIfc align="center">](https://drive.google.com/uc?id=1CG1uuDgnNxqcrkq-jbffw5Hn4SfSiDQE)

**Owner's Name**: Prasanta Kundu

#Version History

Version Number | Author  | Reviewed By | Reason for change 
--- | --- | --- | --- 
Draft 1 | Team_Delta | Prasanta Kundu | 1. Taken baseline from 5 Algorithms Analysis_Nitin Notebook 
--- | --- | --- |2. Shared review comments
Draft 2 | Team_Delta | --- | Incorporated changes after comments on draft 1
--- | --- | Prasanta Kundu | 2. Shared review comments on draft 2
Draft 3 | Team_Delta | --- | To incorporate changes as per comments on draft 2
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install pmdarima 
## installing pmdarima

"""# Importing Python Libraries"""

import pandas as pd
import pandas.util.testing as tm
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import datetime
from sklearn.metrics import mean_squared_error
from math import sqrt
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.ensemble import RandomForestRegressor
from xgboost.sklearn import XGBRegressor
from statsmodels.tsa.holtwinters import ExponentialSmoothing
import statsmodels.tsa.api as smt
import statsmodels.api as sm
from statsmodels.tools.eval_measures import mse,rmse,meanabs
from statsmodels.tsa.arima_model import ARMA,ARMAResults,ARIMA,ARIMAResults
import fbprophet
from fbprophet import Prophet
import keras
from keras.layers import Dense
from keras.models import Sequential
from keras.layers import LSTM
from keras.utils import np_utils
from keras.optimizers import Adam 
from keras.callbacks import EarlyStopping
from sklearn.model_selection import KFold, cross_val_score, train_test_split
import pickle
import warnings
warnings.filterwarnings('ignore')

"""covid 19 data use for 5 alogorithm
Comparing Linear Regression, Random Forest Regression,
 XGBoost, LSTMs, and ARIMA Time Series Forecasting

# Reading COVID-19 datasets
"""

df_confirmed = pd.read_csv("/content/time_series_covid19_confirmed_global.csv",parse_dates=True)
df_recovered = pd.read_csv("/content/time_series_covid19_recovered_global.csv",parse_dates=False)
df_deaths = pd.read_csv("/content/time_series_covid19_deaths_global.csv",parse_dates=False)

df_confirmed.rename(columns={'Country/Region':'Country'}, inplace=True)

df_recovered.rename(columns={'Country/Region':'Country'}, inplace=True)

df_deaths.rename(columns={'Country/Region':'Country'}, inplace=True)

df_confirmed.head()

df_recovered.head()

df_deaths.head()

"""# Exploratory Data Analysis (EDA)"""

max_case_count=pd.DataFrame(df_confirmed.groupby(['Country'])['5/24/20'].mean().reset_index())
max_case_count=max_case_count.sort_values(by='5/24/20',ascending=False)
max_case_count

confirmed = df_confirmed.drop(['Province/State', 'Lat','Long'], axis=1)
recovered = df_recovered.drop(['Province/State', 'Lat','Long'], axis=1)
deaths= df_deaths.drop(['Province/State', 'Lat','Long'], axis=1)

confirmed.set_index('Country',inplace=True)
confirmed = confirmed.transpose()
recovered.set_index('Country',inplace=True)
recovered = recovered.transpose()
deaths.set_index('Country',inplace=True)
deaths = deaths.transpose()

deaths=deaths.rename_axis(None, axis=1).rename_axis('Date', axis=0)
recovered=recovered.rename_axis(None, axis=1).rename_axis('Date', axis=0)
confirmed=confirmed.rename_axis(None, axis=1).rename_axis('Date', axis=0)

deaths['Total']= df_deaths.sum(axis=1)
recovered['Total']= df_recovered.sum(axis=1)
confirmed['Total']= confirmed.sum(axis=1)

deaths= deaths.sort_values(by='5/24/20', ascending=False, axis=1)
recovered=recovered.sort_values(by='5/24/20', ascending=False, axis=1)
confirmed=confirmed.sort_values(by='5/24/20', ascending=False, axis=1)
confirmed.tail(10)

#Checking missing values for 'confirmed' cases
confirmed.reset_index(inplace=True)
confirmed.isnull().sum()

#Converting Date column to datetime object 
confirmed['Date'] = pd.to_datetime(confirmed['Date'])
confirmed.info()

confirmed_total=confirmed[['Date','Total']]
confirmed_total=confirmed_total.rename(columns={'Total': 'Confirmed'})  #Prasanta - what is being done over here -  please check the result
confirmed_total.head(5)

confirmed_total.reset_index(inplace=True)
confirmed_total.isnull().sum()

confirmed_total.info()

"""## Checking **confirmed** case counts found in America (US), Brazil, Spain, Italy and India"""

#Confirmed cases in US
US_confirmed= confirmed[['Date','US']]
US_confirmed=US_confirmed.rename(columns={'US': 'Confirmed'}) 
US_confirmed.tail()

#Confirmed cases in Brazil
Brazil_confirmed = confirmed[['Date','Brazil']]
Brazil_confirmed.tail()

#Confirmed cases in Spain
Spain_confirmed = confirmed[['Date','Spain']]
Spain_confirmed=Spain_confirmed.rename(columns={'Spain': 'Confirmed'}) 
Spain_confirmed.tail()

#Confirmed cases in Italy
Italy_confirmed = confirmed[['Date','Italy']]
Italy_confirmed=Italy_confirmed.rename(columns={'Italy': 'Confirmed'}) 
Italy_confirmed.tail()

#Confirmed cases in India
India_confirmed = confirmed[['Date','India']]
India_confirmed=India_confirmed.rename(columns={'India': 'Confirmed'}) 
India_confirmed.tail()

"""##Data Visualization

Visualising the spread geographically

How the Coronavirus cases are rising?
"""

import plotly
import plotly.graph_objects as go
import plotly.express as px
plotly.io.renderers.default = 'colab'

#Learn how to create interactive graphs using plotly
# Rise of COVID-19 cases in America
fig = go.Figure()
fig.add_trace(go.Scatter(x=US_confirmed['Date'], y = US_confirmed['Confirmed'], mode='lines+markers',name='Total Cases'))
fig.update_layout(title_text='Trend of Coronavirus Cases in America (Cumulative cases)',plot_bgcolor='rgb(230, 230, 230)')
fig.show()

# New COVID-19 cases reported daily in India

fig = px.bar(US_confirmed, x="Date", y="Confirmed", barmode='group', height=400)
fig.update_layout(title_text='Coronavirus Cases in India on daily basis',plot_bgcolor='rgb(230, 230, 230)')

fig.show()

#Learn how to create interactive graphs using plotly
# Rise of COVID-19 cases in India
fig = go.Figure()
fig.add_trace(go.Scatter(x=India_confirmed['Date'], y = India_confirmed['Confirmed'], mode='lines+markers',name='Total Cases'))
fig.update_layout(title_text='Trend of Coronavirus Cases in India (Cumulative cases)',plot_bgcolor='rgb(230, 230, 230)')
fig.show()

# New COVID-19 cases reported daily in India

fig = px.bar(India_confirmed, x="Date", y="Confirmed", barmode='group', height=400)
fig.update_layout(title_text='Coronavirus Cases in India on daily basis',plot_bgcolor='rgb(230, 230, 230)')

fig.show()

#Learn how to create interactive graphs using plotly
# Rise of COVID-19 cases in India
fig = go.Figure()
fig.add_trace(go.Scatter(x=India_confirmed['Date'], y = India_confirmed['Confirmed'], mode='lines+markers',name='Total Cases'))
fig.update_layout(title_text='Trend of Coronavirus Cases in India (Cumulative cases)',plot_bgcolor='rgb(230, 230, 230)')
fig.show()

# New COVID-19 cases reported daily in India

fig = px.bar(India_confirmed, x="Date", y="Confirmed", barmode='group', height=400)
fig.update_layout(title_text='Coronavirus Cases in India on daily basis',plot_bgcolor='rgb(230, 230, 230)')

fig.show()

"""Prasanta -  Can we have an interactive data visualizations for above analysis. We can have mutiple graphs for all 3 cases across countries, which is missing here

#Building Forecasting Models by applying different algorithms

#**Best forcasting module  in confirmed cases in globle world** - Prasanta to be used later
"""

#Defining function for monthly confirmed cases
def country_cases(data):
    country_data = data.copy()
    country_data.Date = country_data.Date.apply(lambda x: str(x)[:-3])
    country_data = country_data.groupby('Date')['Confirmed'].sum().reset_index()
    country_data.Date = pd.to_datetime(country_data.Date)
    return country_data

country_df = country_cases(confirmed_total)
country_df.head()

#Defining function for monthly confirmed cases per day
def confirmed_cases_per_day():
    fig, ax = plt.subplots(figsize=(7,4))
    plt.hist(country_df.Confirmed, color='mediumblue')
    
    ax.set(xlabel = "confirmed Per day",
           ylabel = "Cases",
           title = "Distrobution of confirmred cases Per Day")
    
confirmed_cases_per_day()

# Average monthly confirmed cases at global level
avg_country_cases = country_df.Confirmed.mean()
print(f"Overall average country confirmed cases: {avg_country_cases}cases")   #Prasanta - please check the data format

"""##Determining 'Stationarity' of Time series data"""

#Defining function for time series analysis
def time_plot(data, x_col, y_col, title):
    fig, ax = plt.subplots(figsize=(15,5))
    sns.lineplot(x_col, y_col, data=data, ax=ax, color='mediumblue', label='Total cases')
    
    second = data.groupby(data.Date.dt.year)[y_col].mean().reset_index()
    second.Date = pd.to_datetime(second.Date, format='%Y')
    sns.lineplot((second.Date + datetime.timedelta(365/12)), y_col, data=second, ax=ax, color='red', label='Mean cases')   
    
    ax.set(xlabel = "Date",
           ylabel = "confirmed",
           title = title)
    
    sns.despine()

time_plot(country_df, 'Date', 'Confirmed','Globle country confirmed cases Before Diff Transformation')

"""Prasanta - Please check to ensure that all the graphical plots have defined Title on the top of the graph as applicable"""

#Defining function for differencing? Please check
def get_diff(data):
    data['Confirmed_diff'] = data.Confirmed.diff()
    data = data.dropna()
    
    return data

stationary_df = get_diff(country_df)
stationary_df

time_plot(stationary_df, 'Date', 'Confirmed_diff', 'Globle country confirmed cases After Diff Transformation')  #Please check y-axis labels - not clear

"""##Visualizing Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) of time series"""

def plots(data, lags=None):
    
    # Convert dataframe to datetime index
    dt_data = data.set_index('Date').drop('Confirmed', axis=1)
    dt_data.dropna(axis=0)
    
    layout = (1, 3)
    raw  = plt.subplot2grid(layout, (0, 0))
    acf  = plt.subplot2grid(layout, (0, 1))
    pacf = plt.subplot2grid(layout, (0, 2))
    
    dt_data.plot(ax=raw, figsize=(12, 5), color='mediumblue')
    smt.graphics.plot_acf(dt_data, lags=lags, ax=acf, color='mediumblue')
    smt.graphics.plot_pacf(dt_data, lags=lags, ax=pacf, color='mediumblue')
    sns.despine()
    plt.tight_layout()

plots(stationary_df, lags=24);  #Prasanta - why this semi colon is here

"""Prasanta - Can we summarize the observations from the graphical plots

##Preparing Dataset Modeling
"""

#create dataframe for transformation from time series to supervised
def generate_supervised(data):
    supervised_df = data.copy()
    
    #create column for each lag
    for i in range(1,24):
        col_name = 'lag_' + str(i)
        supervised_df[col_name] = supervised_df['Confirmed_diff'].shift(i)
    
    #drop null values
    supervised_df = supervised_df.dropna().reset_index(drop=True)
    
   # supervised_df.to_csv('../data/model_df.csv', index=False)
    
    return supervised_df

model_df = generate_supervised(stationary_df)
model_df.head()

#Defining function for data preprocessing for ARIMA
def generate_arima_data(data):
    dt_data = stationary_df.set_index('Date').drop('Confirmed', axis=1)    #Prasanta - why is stationary_df used inside the function?
    dt_data.dropna(axis=0)
    
    #dt_data.to_csv('../data/arima_df.csv')
    
    return dt_data

datetime_df = generate_arima_data(stationary_df)
datetime_df.head()

#Function for Train-Test split
def tts(data):
    data = data.drop(['Date','Confirmed'],axis=1)
    train, test = data[:-24].values, data[-24:].values  
     #Prasanta - need to understand how the sub-set of data is taken
    ##Needs to be configurable values as timeseries data cant use random splitting of data using test train split method 
    return train, test

train, test = tts(model_df)

train.shape

test.shape

#Function for sclaing the data 
def scale_data(train_set, test_set):
    #apply Min Max Scaler
    scaler = MinMaxScaler(feature_range=(-1, 1))
    scaler = scaler.fit(train_set)
    
    # reshape training set
    train_set = train_set.reshape(train_set.shape[0], train_set.shape[1])
    train_set_scaled = scaler.transform(train_set)
    
    # reshape test set
    test_set = test_set.reshape(test_set.shape[0], test_set.shape[1])
    test_set_scaled = scaler.transform(test_set)
    
    X_train, y_train = train_set_scaled[:, 1:], train_set_scaled[:, 0:1].ravel()
    X_test, y_test = test_set_scaled[:, 1:], test_set_scaled[:, 0:1].ravel()
    
    return X_train, y_train, X_test, y_test, scaler

X_train, y_train, X_test, y_test, scaler_object = scale_data(train, test)

"""##Defining Functions for model building"""

#Bringing the data back to original scale
def undo_scaling(y_pred, x_test, scaler_obj, lstm=False):  
    #reshape y_pred
    y_pred = y_pred.reshape(y_pred.shape[0], 1, 1)
    
    if not lstm:
        x_test = x_test.reshape(x_test.shape[0], 1, x_test.shape[1])
    
    #rebuild test set for inverse transform
    pred_test_set = []
    for index in range(0,len(y_pred)):
        pred_test_set.append(np.concatenate([y_pred[index],x_test[index]],axis=1))
        
    #reshape pred_test_set
    pred_test_set = np.array(pred_test_set)
    pred_test_set = pred_test_set.reshape(pred_test_set.shape[0], pred_test_set.shape[2])
    
    #inverse transform
    pred_test_set_inverted = scaler_obj.inverse_transform(pred_test_set)
    
    return pred_test_set_inverted

#Function for loading the original time series dataframe after converting to datetime object  - Added by Prasanta
def load_original_df():
    #load in original dataframe without scaling applied
    original_df = country_df          #Prasanta - where did we create 'monthly_df' dataframe in above?
    original_df.Date = original_df.Date.apply(lambda x: str(x)[:-3])
    original_df = original_df.groupby('Date')['Confirmed'].sum().reset_index()
    original_df.Date = pd.to_datetime(original_df.Date)
    #df['Timestamp'] = pd.to_datetime(df['Year'],format='%Y') 
    return original_df

#Function for time series prediction
def predict_df(unscaled_predictions, original_df):
    #create dataframe that shows the predicted cases
    result_list = []
    cases_dates = list(original_df[-26:].Date)    #Prasanta - Need to understand why the index of original_df is -14; earlier it was -12? why different now?
    act_confirmed = list(original_df[-26:].Confirmed)   #Prasanta - same as above

    for index in range(0,len(unscaled_predictions)):
        result_dict = {}
        result_dict['pred_value'] = int(unscaled_predictions[index][0] + act_confirmed[index])
        result_dict['Date'] = cases_dates[index+1]
        result_list.append(result_dict)
        
    df_result = pd.DataFrame(result_list)
        
    return df_result

#Function for obtaining accuracy scores
model_scores = {}   #Prasanta - Is it a list or dictionary???

def get_scores(unscaled_df, original_df, model_name):
    rmse = np.sqrt(mean_squared_error(original_df.Confirmed[-24:], unscaled_df.pred_value[-24:]))
    mae = mean_absolute_error(original_df.Confirmed[-24:], unscaled_df.pred_value[-24:])
    r2 = r2_score(original_df.Confirmed[-24:], unscaled_df.pred_value[-24:])
    model_scores[model_name] = [rmse, mae, r2]

    print(f"RMSE: {rmse}")
    print(f"MAE: {mae}")
    print(f"R2 Score: {r2}")

#Function for visualizing the results for respective models
def plot_results(results, original_df, model_name):

    fig, ax = plt.subplots(figsize=(15,5))
    sns.lineplot(original_df.Date, original_df.Confirmed, data=original_df, ax=ax,label='Original', color='mediumblue')
    sns.lineplot(results.Date, results.pred_value, data=results, ax=ax,label='Predicted', color='Red')
    
    ax.set(xlabel = "Date",
           ylabel = "Confirmed",
           title = f"{model_name} Corona Forecasting Prediction")
    
    ax.legend()
    
    sns.despine()   #Removes top and right spines from the plots
    
    plt.savefig(f'/content/{model_name}_forecast.png')

#Function for executing the model to be used for comparison
def run_model(train_data, test_data, model, model_name):       
  #Prasanta - what is that value being passed when we use 'model' as a paramater into the function?
    
    X_train, y_train, X_test, y_test, scaler_object = scale_data(train_data, test_data)
    
    mod = model   #Here model represents the respective algorithms
    mod.fit(X_train, y_train)
    predictions = mod.predict(X_test)
    
    # Undo scaling to compare predictions against original data
    original_df = load_original_df()
    unscaled = undo_scaling(predictions, X_test, scaler_object)
    unscaled_df = predict_df(unscaled, original_df)
      
    get_scores(unscaled_df, original_df, model_name)
    
    plot_results(unscaled_df, original_df, model_name)

"""##Linear Regression"""

#Applying Linear Regression on time series data
run_model(train, test, LinearRegression(), 'LinearRegression')

"""##Random Forest Regressor"""

#Applying Random Forest (RF) Regressor on time series data
run_model(train, test, RandomForestRegressor(n_estimators=100, max_depth=20),'RandomForest')

"""XGBoost Regressor"""

#Applying XGBoost Regressor on time series data
run_model(train, test, XGBRegressor( n_estimators=100, learning_rate=0.2, objective='reg:squarederror'), 'XGBoost')

"""LSTM (Deep Learning) Model"""

#Applying LSTM Model on time series data
#Function for Model build, training and prediction for LSTM Model
def lstm_model(train_data, test_data):
    
    X_train, y_train, X_test, y_test, scaler_object = scale_data(train_data, test_data)
    
    X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])
    X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])
   
    model = Sequential()
    model.add(LSTM(4, batch_input_shape=(1, X_train.shape[1], X_train.shape[2]), 
                   stateful=True))
    model.add(Dense(1))
    model.add(Dense(1))
    model.compile(loss='mean_squared_error', optimizer='adam')
    model.fit(X_train, y_train, epochs=200, batch_size=1, verbose=1, 
              shuffle=False)
    predictions = model.predict(X_test,batch_size=1)
    
    original_df = country_df
    unscaled = undo_scaling(predictions, X_test, scaler_object, lstm=True)
    unscaled_df = predict_df(unscaled, original_df)
    
    get_scores(unscaled_df, original_df, 'LSTM')
    
    plot_results(unscaled_df, original_df, 'LSTM')

lstm_model(train, test)

pickle.dump(model_scores, open( "model_scores.p", "wb" ) )

"""ARIMA Model"""

from pmdarima import auto_arima

ts_data = datetime_df

ts_data.index = pd.to_datetime(ts_data.index)   #Prasanta - Need to understand what we are doing over here
ts_data.reset_index(inplace=True)
ts_data.head()

train_data_arima = ts_data.iloc[:-24]   #Prasanta - Need to understand what exactly we are doing here. We have done it before other way!!!
test_data_arima=ts_data.iloc[-24:]       #Why we are not using the function that we already defined for train-test split tts()

#Prasanta - we may not need to define this function. With auto-arima we should be able to figure out p, d, q values 
#which can be used for defining model-arima() function
def model_arima(data):
  stepwise_fit = auto_arima(data['Confirmed_diff'], start_p=0, start_q=0,     #Prasanta - Would it not be ts_data[]???
                          max_p=6, max_q=6, m=7,
                          seasonal=False,
                          d=None, trace=True,
                          error_action='ignore',   # we don't want to know if an order does not work
                          suppress_warnings=True,  # we don't want convergence warnings
                          stepwise=True)        # set to stepwise
  stepwise_fit.plot_diagnostics(figsize=(10, 8));    #Prasanta - why semi colon here?
  stepwise_fit.summary()

model_arima(ts_data)

"""Note : Choose the lowest AIC value order

**Prasanta - Can we summarize the observations from the graphical plots**
"""

#Function for forecasting by ARIMA Model
#Prasanta - Should it not be arima_model() function similar to lstm_model()???

def arima_predictions(train,test,p,d,q):
  order=(p,d,q)
  model_arima = ARIMA(train['Confirmed_diff'].astype(float),order=order)
  results_arima = model_arima.fit()
  #  predictions
  start=len(train)
  end=len(train)+len(test)-1
  predictions_arima = results_arima.predict(start=start, end=end, dynamic=False, typ='levels').rename('ARIMA(0,2,1) Predictions')
  get_scores_arima(test,predictions_arima)         #Prasanta - How do we arrive at ARIMA(0,2,1) which needs to be shown before
  plot_results(train,test, predictions_arima, 'Arima_forecast')   #Prasanta - Please check the 3 parameters to be passed in both get_scores and plot_results
  #ts_data.iloc[:,1].plot(legend=True,figsize=(12,6));            #Seems to be something gone wrong in above 2 line of codes
  #predictions_arima.plot(legend=True,figsize=(12,6));            #as both functions must either be re-used or defined (if at all needed)
  #test.iloc[:,1].plot(legend=True,figsize=(12,6));               #prior to arima_predictions() 
  
  #print(type(predictions_arima))
  #return predictions_arima

def get_scores_arima(expected,predicted):  #Prasanta - Can we not re-use the same get_scores function in ARIMA?
    
    model_scores = {}
    
    rmse = np.sqrt(mean_squared_error(expected.iloc[:,1], predicted))
    mae = mean_absolute_error(expected.iloc[:,1],predicted)
    r2 = r2_score(expected.iloc[:,1], predicted)
    
    model_scores['ARIMA'] = [rmse, mae, r2]
    
    print(f"RMSE: {rmse}")
    print(f"MAE: {mae}")
    print(f"R2 Score: {r2}")
    
    pickle.dump(model_scores, open( "arima_model_scores.p", "wb" ))

def plot_results(train,test,predictions,model_name):   #Prasanta - Can we not re-use the same get_scores function in ARIMA?


    fig, ax = plt.subplots(figsize=(15,5))
    sns.lineplot(train.Date, train.Confirmed_diff, data=train, ax=ax,label='Original train', color='mediumblue')
    sns.lineplot(test.Date, test.Confirmed_diff, data=test, ax=ax,label='Original test', color='mediumblue')
    sns.lineplot(test.Date, predictions, data=test, ax=ax,label='predictions', color='Red')
    
    ax.set(xlabel = "Date",
           ylabel = "Confirmed",
           title = f"{model_name} corona Forecasting Prediction")
    
    ax.legend()
    
    sns.despine()
    plt.savefig(f'/content/{model_name}_forecast.png')

arima_predictions(train_data_arima,test_data_arima,0,1,1)

def plot_results(train,test,predictions,model_name):    #Prasanta - Is this defined specific to Prophet model?
                                                        #It seems to be duplicated. Please check

    fig, ax = plt.subplots(figsize=(15,5))
    sns.lineplot(train.Date, train.Confirmed_diff, data=train, ax=ax,label='Original train', color='mediumblue')
    sns.lineplot(test.Date, test.Confirmed_diff, data=test, ax=ax,label='Original test', color='mediumblue')
    sns.lineplot(test.Date, predictions, data=test, ax=ax,label='predictions', color='Red')
    
    ax.set(xlabel = "Date",
           ylabel = "Confirmed",
           title = f"{model_name} corona Forecasting Prediction")
    
    ax.legend()
    
    sns.despine()
    plt.savefig(f'/content/{model_name}_forecast.png')

"""SARIMAX module"""

def get_scores(data):
    
    model_scores = {}
    
    rmse = np.sqrt(mean_squared_error(data.Confirmed_diff[-24:], data.forecast[-24:]))
    mae = mean_absolute_error(data.Confirmed_diff[-24:], data.forecast[-24:])
    r2 = r2_score(data.Confirmed_diff[-24:], data.forecast[-24:])
    model_scores['SARIMAX'] = [rmse, mae, r2]
    
    print(f"RMSE: {rmse}")
    print(f"MAE: {mae}")
    print(f"R2 Score: {r2}")
    
    pickle.dump(model_scores, open( "sarimax_model_scores.p", "wb" ))

'''
def sarimax_model(data):
    
    # Model
    sar = sm.tsa.statespace.SARIMAX(ts_data.Confirmed_diff, order=(12,0,0), seasonal_order=(0,1,0,12), trend='c').fit()

    # Predictions
    start, end, dynamic = 90, 122, 7    #Prasanta - why these values are hard coded here
    data['forecast'] = sar.predict(start=start, end=end, dynamic=dynamic) 
    pred_df = data.forecast[start+dynamic:end]
    
    data[['Confirmed_diff', 'forecast']].plot(color=['mediumblue', 'Red'])
    
    get_scores(data)

    return sar, data, pred_df

sar, ts_data, predictions = sarimax_model(ts_data)

'''

"""since there is no seasonality we are not considering SARIMAX in the resuts table"""

sar.plot_diagnostics(figsize=(10, 8));

"""Plot Results"""

def predict_df(prediction_df):
    
    #load in original dataframe without scaling applied
    original_df = country_df
   # original_df.Date = original_df.Date.apply(lambda x: str(x)[:-3])
   # original_df = original_df.groupby('Date')['Confirmed'].sum().reset_index()
   # original_df.Date = pd.to_datetime(original_df.Date)
    
    #create dataframe that shows the predicted sales
    result_list = []
    conf_dates = list(original_df[-26:].Date)
    act_conf = list(original_df[-26:].Confirmed)
    
    for index in range(0,len(prediction_df)):
        result_dict = {}
        result_dict['pred_value'] = int(prediction_df[index] + act_conf[index])
        result_dict['Date'] = conf_dates[index+1]
        result_list.append(result_dict)
        
    df_result = pd.DataFrame(result_list)
    
    return df_result, original_df

def plot_results(results, original_df, model_name):

    fig, ax = plt.subplots(figsize=(15,5))
    sns.lineplot(original_df.Date, original_df.Confirmed, data=original_df, ax=ax,label='Original', color='mediumblue')
    sns.lineplot(results.Date, results.pred_value, data=results, ax=ax,label='Predicted', color='Red')
    
    ax.set(xlabel = "Date",
           ylabel = "Confirmed",
           title = f"{model_name} corona Forecasting Prediction")
    
    ax.legend()
    
    sns.despine()
#plt.savefig(f'/content/{model_name}_forecast.png')

#prediction_df, original_df = predict_df(predictions)

#plot_results(prediction_df, original_df, 'sarimax')

"""##Prophet Model"""

prophet_data=country_df.copy()
prophet_data.reset_index(inplace=True)
prophet_data.head()

train_df= prophet_data[:-24]
test_df=prophet_data[-24:]
train_confirmed= pd.DataFrame()
train_confirmed['ds'] = train_df['Date']
train_confirmed['y']= train_df['Confirmed']
model = Prophet()
model.fit(train_confirmed)
future_dates = model.make_future_dataframe(periods=24)
prediction = model.predict(future_dates)

# Plot Our Prediction
model.plot(prediction)

# Visualize Each Component [Trends,Weekly]
model.plot_components(prediction)

rmse = np.sqrt(mean_squared_error(test_df.Confirmed[-24:], prediction.yhat[-24:]))
mae = mean_absolute_error(test_df.Confirmed[-24:], prediction.yhat[-24:])
r2 = r2_score(test_df.Confirmed[-24:], prediction.yhat[-24:])
example_dict = {}
example_dict['Prophet'] = [rmse, mae, r2]
test_df['Confirmed'].plot(legend=True,label='ORIGINAL',figsize=(12,5));
prediction['yhat'].plot(legend=True,label='PREDICTION'); 
pickle_out = open("prophet_model_scores.p","wb")
pickle.dump(example_dict, pickle_out)
pickle_out.close()
pickle_in = open("prophet_model_scores.p","rb")
example_dict = pickle.load(pickle_in)
print(f"RMSE: {rmse}")
print(f"MAE: {mae}")
print(f"R2 Score: {r2}")

pickle_in = open("prophet_model_scores.p","rb")
prophet_dict = pickle.load(pickle_in)
print(prophet_dict)

"""##Holt Winter Model"""

def get_data(data):
    dt_data = data.set_index('Date').drop('Confirmed_diff', axis=1)
    dt_data.dropna(axis=0)   #Prasanta - Should we not check the null or missing values first before we remove. 
                             #In my view this should be common for all models and should be used as part of data pre-processing
                             #This doesn't necessarily be a function  
    #dt_data.to_csv('../data/arima_df.csv')
    
    return dt_data

holt_data=get_data(country_df)
holt_data.reset_index(inplace=True)
holt_data.head()

def holt(data,model_name):
  train_data=data[:-24]        #Prasanta - why the index value is -24 here, it should be same as before. Please check
  test_data =data[-24:]
  train_data.drop(columns='Date',inplace=True)
  test_data.drop(columns='Date',inplace=True)
  holt_data['Double ES'] = ExponentialSmoothing(holt_data['Confirmed'].astype(float),trend='add').fit().fittedvalues
  #holt_data[['Confirmed','Triple ES']].plot(figsize=(12,5))
  fitted_model = ExponentialSmoothing(train_data['Confirmed'].astype(float),trend='add').fit()
  test_predictions= fitted_model.forecast(24).rename(f'{model_name} Forecast')
  train_data['Confirmed'].plot(figsize=(12,5),legend=True,label='Train')
  test_data['Confirmed'].plot(legend=True,label='Test',figsize=(12,5));
  test_predictions.plot(legend=True,label='Prediction');  
  get_scores_holt(test_data['Confirmed'],test_predictions,model_name)     #I believe we should be able to use same get_scores() here
                                                                          #Need to understand why we would need to customize this
                                                                          #function for Holt Winter model?
                                                                          #Moreoever get_scores() must be defined first before it 
                                                                          #can be called over here

def get_scores_holt(test_data,predictions,model_name):
  model_name_dict = {}
  #model_scores = {}
  rmse = np.sqrt(mean_squared_error(test_data,predictions))
  mae = mean_absolute_error(test_data,predictions)
  r2 = r2_score(test_data,predictions)
  #model_scores['Holt Winter'] = [rmse, mae, r2]
  model_name_dict[f'{model_name}'] = [rmse, mae, r2]
  pickle_out = open(f'{model_name}_model_scores.p',"wb")    #Prasanta - Writing data into a pickle file should be common for all models
  pickle.dump(model_name_dict, pickle_out)                      #Please check across the models as to how it can be generalized
  pickle_out.close()
  pickle_in = open(f'{model_name}_model_scores.p',"rb")         #Prasanta - Reading/loading data from a pickle file should be common for all models
  model_name_dict = pickle.load(pickle_in)
  print(model_name_dict)
  print(f"RMSE: {rmse}")
  print(f"MAE: {mae}")
  print(f"R2 Score: {r2}")
 # pickle.dump(model_scores, open( "Holt_model_scores.p", "wb" ))

holt(holt_data,'Holt')

pickle_in = open("Holt_model_scores.p","rb")      #Prasanta - this seems to be logical as same operation can be applied
holtwinter_dict = pickle.load(pickle_in)          #to all other forecasting models in the similar way
print(holtwinter_dict)

"""##**Create Results Dataframe**"""

def create_results_df():
    results_dict = pickle.load(open("model_scores.p", "rb"))
    
    
    results_dict.update(pickle.load(open("arima_model_scores.p", "rb")))

    results_dict.update(pickle.load(open("sarimax_model_scores.p", "rb")))


    results_dict.update(pickle.load(open("prophet_model_scores.p", "rb")))

    results_dict.update(pickle.load(open("Holt_model_scores.p", "rb")))

    restults_df = pd.DataFrame.from_dict(results_dict, orient='index', 
                                        columns=['RMSE', 'MAE','R2'])
    
    restults_df = restults_df.sort_values(by='RMSE', ascending=False).reset_index()
    
    return restults_df
    create_results_df.to_csv('confirmed_index_df.csv')

results = create_results_df()
results

#results.to_csv('confirmed_index.csv')

"""**Plot Results**"""

def plot_results(results_df):
    fig, ax = plt.subplots(figsize=(12, 5))
    sns.lineplot(np.arange(len(results_df)), 'RMSE', data=results_df, ax=ax, 
                 label='RMSE', color='mediumblue')
    sns.lineplot(np.arange(len(results_df)), 'MAE', data=results_df, ax=ax, 
                 label='MAE', color='Cyan')
    sns.lineplot(np.arange(len(results_df)), 'R2', data=results_df, ax=ax, 
                 label='R2', color='Green')
    
    plt.xticks(np.arange(len(results_df)),rotation=45)
    ax.set_xticklabels(results_df['index'])
    ax.set(xlabel = "Model",
           ylabel = "Scores",
           title = "Model Error Comparison")
    sns.despine()
plt.savefig(f'/content/models_forecast.png')

plot_results(results)

#plt.savefig('results_forecast.png')

average_country_confirmed_cases= 89193.08064516129
gboost = 34463.973146
percentage_off = round(gboost/average_country_confirmed_cases*100, 2)

print(f"With XGBoost, prediction is within {percentage_off}% of the actual.")

"""**Best forcasting module  in America confirmed cases in globle world**"""

#Defining function for country confirmed cases
def country_cases(data):
    country_data = data.copy()
    country_data.Date = country_data.Date.apply(lambda x: str(x)[:-3])
    country_data = country_data.groupby('Date')['Confirmed'].sum().reset_index()
    country_data.Date = pd.to_datetime(country_data.Date)
    return country_data

country_df = country_cases(US_confirmed)
country_df.tail()

def confirmed_cases_per_day():
    fig, ax = plt.subplots(figsize=(7,4))
    plt.hist(country_df.Confirmed, color='mediumblue')
    
    ax.set(xlabel = "confirmed Per day",
           ylabel = "Cases",
           title = "Distrobution of confirmred cases Per Day in America")
    
confirmed_cases_per_day()

# Average country confirmed cases

# Overall
avg_country_cases = country_df.Confirmed.mean()
print(f"Overall America average country confirmed cases: {avg_country_cases}cases")

"""Determining Stationarity"""

'''
def time_plot(data, x_col, y_col, title):
    fig, ax = plt.subplots(figsize=(15,5))
    sns.lineplot(x_col, y_col, data=data, ax=ax, color='mediumblue', label='Total cases')
    
    second = data.groupby(data.Date.dt.year)[y_col].mean().reset_index()
    second.Date = pd.to_datetime(second.Date, format='%Y')
    sns.lineplot((second.Date + datetime.timedelta(365/12)), y_col, data=second, ax=ax, color='red', label='Mean cases')   
    
    ax.set(xlabel = "Date",
           ylabel = "confirmed",
           title = title)
    
    sns.despine()
'''

time_plot(country_df, 'Date', 'Confirmed','America country confirmed cases Before Diff Transformation')

def get_diff(data):
    data['Confirmed_diff'] = data.Confirmed.diff()
    data = data.dropna()
    
    return data

stationary_df = get_diff(country_df)

time_plot(stationary_df, 'Date', 'Confirmed_diff', 'America country cases After Diff Transformation')

def plots(data, lags=None):
    
    # Convert dataframe to datetime index
    dt_data = data.set_index('Date').drop('Confirmed', axis=1)
    dt_data.dropna(axis=0)
    
    layout = (1, 3)
    raw  = plt.subplot2grid(layout, (0, 0))
    acf  = plt.subplot2grid(layout, (0, 1))
    pacf = plt.subplot2grid(layout, (0, 2))
    
    dt_data.plot(ax=raw, figsize=(12, 5), color='mediumblue')
    smt.graphics.plot_acf(dt_data, lags=lags, ax=acf, color='mediumblue')
    smt.graphics.plot_pacf(dt_data, lags=lags, ax=pacf, color='mediumblue')
    sns.despine()
    plt.tight_layout()

plots(stationary_df, lags=24);

"""Preparing Dataset Modeling"""

#create dataframe for transformation from time series to supervised
def generate_supervised(data):
    supervised_df = data.copy()
    
    #create column for each lag
    for i in range(1,24):
        col_name = 'lag_' + str(i)
        supervised_df[col_name] = supervised_df['Confirmed_diff'].shift(i)
    
    #drop null values
    supervised_df = supervised_df.dropna().reset_index(drop=True)
    
   # supervised_df.to_csv('../data/model_df.csv', index=False)
    
    return supervised_df

model_df = generate_supervised(stationary_df)
model_df.tail()

"""**ARIMA Modeling**"""

def generate_arima_data(data):
    dt_data = data.set_index('Date').drop('Confirmed', axis=1)
    dt_data.dropna(axis=0)
    
    #dt_data.to_csv('../data/arima_df.csv')
    
    return dt_data

datetime_df = generate_arima_data(stationary_df)
datetime_df.tail()

"""Train Test Split"""

def tts(data):
    data = data.drop(['Date','Confirmed'],axis=1)
    train, test = data[:-24].values, data[-24:].values
    
    return train, test

train, test = tts(model_df)

train.shape

test.shape

def scale_data(train_set, test_set):
    #apply Min Max Scaler
    scaler = MinMaxScaler(feature_range=(-1, 1))
    scaler = scaler.fit(train_set)
    
    # reshape training set
    train_set = train_set.reshape(train_set.shape[0], train_set.shape[1])
    train_set_scaled = scaler.transform(train_set)
    
    # reshape test set
    test_set = test_set.reshape(test_set.shape[0], test_set.shape[1])
    test_set_scaled = scaler.transform(test_set)
    
    X_train, y_train = train_set_scaled[:, 1:], train_set_scaled[:, 0:1].ravel()
    X_test, y_test = test_set_scaled[:, 1:], test_set_scaled[:, 0:1].ravel()
    
    return X_train, y_train, X_test, y_test, scaler

X_train, y_train, X_test, y_test, scaler_object = scale_data(train, test)

"""Modeling Functions"""

def undo_scaling(y_pred, x_test, scaler_obj, lstm=False):  
    #reshape y_pred
    y_pred = y_pred.reshape(y_pred.shape[0], 1, 1)
    
    if not lstm:
        x_test = x_test.reshape(x_test.shape[0], 1, x_test.shape[1])
    
    #rebuild test set for inverse transform
    pred_test_set = []
    for index in range(0,len(y_pred)):
        pred_test_set.append(np.concatenate([y_pred[index],x_test[index]],axis=1))
        
    #reshape pred_test_set
    pred_test_set = np.array(pred_test_set)
    pred_test_set = pred_test_set.reshape(pred_test_set.shape[0], pred_test_set.shape[2])
    
    #inverse transform
    pred_test_set_inverted = scaler_obj.inverse_transform(pred_test_set)
    
    return pred_test_set_inverted

def load_original_df():
    #load in original dataframe without scaling applied
    original_df = country_df
    original_df.Date = original_df.Date.apply(lambda x: str(x)[:-3])
    original_df = original_df.groupby('Date')['Confirmed'].sum().reset_index()
    original_df.Date = pd.to_datetime(original_df.Date)
    #df['Timestamp'] = pd.to_datetime(df['Year'],format='%Y') 
    return original_df

def predict_df(unscaled_predictions, original_df):
    #create dataframe that shows the predicted cases
    result_list = []
    cases_dates = list(original_df[-26:].Date)
    act_confirmed = list(original_df[-26:].Confirmed)

    for index in range(0,len(unscaled_predictions)):
        result_dict = {}
        result_dict['pred_value'] = int(unscaled_predictions[index][0] + act_confirmed[index])
        result_dict['Date'] = cases_dates[index+1]
        result_list.append(result_dict)
        
    df_result = pd.DataFrame(result_list)
        
    return df_result

model_scores = {}

def get_scores(unscaled_df, original_df, model_name):
    rmse = np.sqrt(mean_squared_error(original_df.Confirmed[-24:], unscaled_df.pred_value[-24:]))
    mae = mean_absolute_error(original_df.Confirmed[-24:], unscaled_df.pred_value[-24:])
    r2 = r2_score(original_df.Confirmed[-24:], unscaled_df.pred_value[-24:])
    model_scores[model_name] = [rmse, mae, r2]

    print(f"RMSE: {rmse}")
    print(f"MAE: {mae}")
    print(f"R2 Score: {r2}")

def plot_results(results, original_df, model_name):

    fig, ax = plt.subplots(figsize=(15,5))
    sns.lineplot(original_df.Date, original_df.Confirmed, data=original_df, ax=ax,label='Original', color='mediumblue')
    sns.lineplot(results.Date, results.pred_value, data=results, ax=ax,label='Predicted', color='Red')
    
    ax.set(xlabel = "Date",
           ylabel = "Confirmed",
           title = f"{model_name} corona Forecasting Prediction")
    
    ax.legend()
    
    sns.despine()
    
    plt.savefig(f'/content/{model_name}_forecast.png')

def run_model(train_data, test_data, model, model_name):
    
    X_train, y_train, X_test, y_test, scaler_object = scale_data(train_data, test_data)
    
    mod = model
    mod.fit(X_train, y_train)
    predictions = mod.predict(X_test)
    
    # Undo scaling to compare predictions against original data
    original_df = load_original_df()
    unscaled = undo_scaling(predictions, X_test, scaler_object)
    unscaled_df = predict_df(unscaled, original_df)
      
    get_scores(unscaled_df, original_df, model_name)
    
    plot_results(unscaled_df, original_df, model_name)

"""**Linear Regression**"""

run_model(train, test, LinearRegression(), 'LinearRegression')

"""**Random Forest Regressor**"""

run_model(train, test, RandomForestRegressor(n_estimators=100, max_depth=20),'RandomForest')

"""**XGBoost**"""

run_model(train, test, XGBRegressor( n_estimators=100, learning_rate=0.2, objective='reg:squarederror'), 'XGBoost')

"""**LSTM**"""

def lstm_model(train_data, test_data):
    
    X_train, y_train, X_test, y_test, scaler_object = scale_data(train_data, test_data)
    
    X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])
    X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])
   
    model = Sequential()
    model.add(LSTM(4, batch_input_shape=(1, X_train.shape[1], X_train.shape[2]), 
                   stateful=True))
    model.add(Dense(1))
    model.add(Dense(1))
    model.compile(loss='mean_squared_error', optimizer='adam')
    model.fit(X_train, y_train, epochs=200, batch_size=1, verbose=1, 
              shuffle=False)
    predictions = model.predict(X_test,batch_size=1)
    
    original_df = country_df
    unscaled = undo_scaling(predictions, X_test, scaler_object, lstm=True)
    unscaled_df = predict_df(unscaled, original_df)
    
    get_scores(unscaled_df, original_df, 'LSTM')
    
    plot_results(unscaled_df, original_df, 'LSTM')

lstm_model(train, test)

pickle.dump(model_scores, open( "model_scores_US.p", "wb" ) )

"""**Arima module**"""



"""##ARIMA Model"""

ts_data = datetime_df

ts_data.index = pd.to_datetime(ts_data.index)   #Prasanta - Need to understand what we are doing over here
ts_data.reset_index(inplace=True)
ts_data.tail()

train_data_arima = ts_data.iloc[:-24]   #Prasanta - Need to understand what exactly we are doing here. We have done it before other way!!!
test_data_arima=ts_data.iloc[-24:]       #Why we are not using the function that we already defined for train-test split tts()

#Prasanta - we may not need to define this function. With auto-arima we should be able to figure out p, d, q values 
#which can be used for defining model-arima() function
def model_arima(data):
  stepwise_fit = auto_arima(data['Confirmed_diff'], start_p=0, start_q=0,     #Prasanta - Would it not be ts_data[]???
                          max_p=6, max_q=6, m=7,
                          seasonal=False,
                          d=None, trace=True,
                          error_action='ignore',   # we don't want to know if an order does not work
                          suppress_warnings=True,  # we don't want convergence warnings
                          stepwise=True)        # set to stepwise
  stepwise_fit.plot_diagnostics(figsize=(10, 8));    #Prasanta - why semi colon here?
  stepwise_fit.summary()

model_arima(ts_data)

"""Note : Choose the lowest AIC value order

**Prasanta - Can we summarize the observations from the graphical plots**
"""

#Function for forecasting by ARIMA Model
#Prasanta - Should it not be arima_model() function similar to lstm_model()???

def arima_predictions(train,test,p,d,q):
  order=(p,d,q)
  model_arima = ARIMA(train['Confirmed_diff'].astype(float),order=order)
  results_arima = model_arima.fit()
  #  predictions
  start=len(train)
  end=len(train)+len(test)-1
  predictions_arima = results_arima.predict(start=start, end=end, dynamic=False, typ='levels').rename('ARIMA(0,2,1) Predictions')
  get_scores_arima(test,predictions_arima)         #Prasanta - How do we arrive at ARIMA(0,2,1) which needs to be shown before
  plot_results(train,test, predictions_arima, 'Arima_forecast')   #Prasanta - Please check the 3 parameters to be passed in both get_scores and plot_results
  #ts_data.iloc[:,1].plot(legend=True,figsize=(12,6));            #Seems to be something gone wrong in above 2 line of codes
  #predictions_arima.plot(legend=True,figsize=(12,6));            #as both functions must either be re-used or defined (if at all needed)
  #test.iloc[:,1].plot(legend=True,figsize=(12,6));               #prior to arima_predictions() 
  
  #print(type(predictions_arima))
  #return predictions_arima

def get_scores_arima(expected,predicted):  #Prasanta - Can we not re-use the same get_scores function in ARIMA?
    
    model_scores = {}
    
    rmse = np.sqrt(mean_squared_error(expected.iloc[:,1], predicted))
    mae = mean_absolute_error(expected.iloc[:,1],predicted)
    r2 = r2_score(expected.iloc[:,1], predicted)
    
    model_scores['ARIMA'] = [rmse, mae, r2]
    
    print(f"RMSE: {rmse}")
    print(f"MAE: {mae}")
    print(f"R2 Score: {r2}")
    
    pickle.dump(model_scores, open( "arima_model_scores_US.p", "wb" ))

def plot_results(train,test,predictions,model_name):   #Prasanta - Can we not re-use the same get_scores function in ARIMA?


    fig, ax = plt.subplots(figsize=(15,5))
    sns.lineplot(train.Date, train.Confirmed_diff, data=train, ax=ax,label='Original train', color='mediumblue')
    sns.lineplot(test.Date, test.Confirmed_diff, data=test, ax=ax,label='Original test', color='mediumblue')
    sns.lineplot(test.Date, predictions, data=test, ax=ax,label='predictions', color='Red')
    
    ax.set(xlabel = "Date",
           ylabel = "Confirmed",
           title = f"{model_name} corona Forecasting Prediction")
    
    ax.legend()
    
    sns.despine()
    plt.savefig(f'/content/{model_name}_forecast.png')

arima_predictions(train_data_arima,test_data_arima,0,1,1)

def plot_results(train,test,predictions,model_name):    #Prasanta - Is this defined specific to Prophet model?
                                                        #It seems to be duplicated. Please check

    fig, ax = plt.subplots(figsize=(15,5))
    sns.lineplot(train.Date, train.Confirmed_diff, data=train, ax=ax,label='Original train', color='mediumblue')
    sns.lineplot(test.Date, test.Confirmed_diff, data=test, ax=ax,label='Original test', color='mediumblue')
    sns.lineplot(test.Date, predictions, data=test, ax=ax,label='predictions', color='Red')
    
    ax.set(xlabel = "Date",
           ylabel = "Confirmed",
           title = f"{model_name} corona Forecasting Prediction")
    
    ax.legend()
    
    sns.despine()
    plt.savefig(f'/content/{model_name}_forecast.png')

"""SARIMAX Modeling"""

def get_scores(data):
    
    model_scores = {}
    
    rmse = np.sqrt(mean_squared_error(data.Confirmed_diff[-24:], data.forecast[-24:]))
    mae = mean_absolute_error(data.Confirmed_diff[-24:], data.forecast[-24:])
    r2 = r2_score(data.Confirmed_diff[-24:], data.forecast[-24:])
    model_scores['SARIMAX'] = [rmse, mae, r2]
    
    print(f"RMSE: {rmse}")
    print(f"MAE: {mae}")
    print(f"R2 Score: {r2}")
    
    pickle.dump(model_scores, open( "sarimax_model_scores_US.p", "wb" ))

def sarimax_model(data):
    
    # Model
    sar = sm.tsa.statespace.SARIMAX(ts_data.Confirmed_diff, order=(12,0,0), seasonal_order=(0,1,0,12), trend='c').fit()

    # Predictions
    start, end, dynamic = 90, 122, 7
    data['forecast'] = sar.predict(start=start, end=end, dynamic=dynamic) 
    pred_df = data.forecast[start+dynamic:end]
    
    data[['Confirmed_diff', 'forecast']].plot(color=['mediumblue', 'Red'])
    
    get_scores(data)

    return sar, data, pred_df

sar, ts_data, predictions = sarimax_model(ts_data)

sar.plot_diagnostics(figsize=(10, 8));

"""## Plot Results"""

def predict_df(prediction_df):
    
    #load in original dataframe without scaling applied
    original_df = country_df
   # original_df.Date = original_df.Date.apply(lambda x: str(x)[:-3])
   # original_df = original_df.groupby('Date')['Confirmed'].sum().reset_index()
   # original_df.Date = pd.to_datetime(original_df.Date)
    
    #create dataframe that shows the predicted sales
    result_list = []
    conf_dates = list(original_df[-26:].Date)
    act_conf = list(original_df[-26:].Confirmed)
    
    for index in range(0,len(prediction_df)):
        result_dict = {}
        result_dict['pred_value'] = int(prediction_df[index] + act_conf[index])
        result_dict['Date'] = conf_dates[index+1]
        result_list.append(result_dict)
        
    df_result = pd.DataFrame(result_list)
    
    return df_result, original_df

def plot_results(results, original_df, model_name):

    fig, ax = plt.subplots(figsize=(15,5))
    sns.lineplot(original_df.Date, original_df.Confirmed, data=original_df, ax=ax,label='Original', color='mediumblue')
    sns.lineplot(results.Date, results.pred_value, data=results, ax=ax,label='Predicted', color='Red')
    
    ax.set(xlabel = "Date",
           ylabel = "Confirmed",
           title = f"{model_name} corona Forecasting Prediction")
    
    ax.legend()
    
    sns.despine()
#plt.savefig(f'/content/{model_name}_forecast.png')

#prediction_df, original_df = predict_df(predictions)

#plot_results(prediction_df, original_df, 'sarimax')

"""#**Prophet module**"""

def get_data(data):
    dt_data = data.set_index('Date').drop('Confirmed_diff', axis=1)
    dt_data.dropna(axis=0)
    
    #dt_data.to_csv('../data/arima_df.csv')
    
    return dt_data

df = get_data(country_df)
df.reset_index(inplace=True)
train_df= df[:-24]
test_df= df[-24:]
train_confirmed= pd.DataFrame()
train_confirmed['ds'] = train_df['Date']
train_confirmed['y']= train_df['Confirmed']
model = Prophet()
model.fit(train_confirmed)
future_dates = model.make_future_dataframe(periods = 24)
prediction = model.predict(future_dates)

# Plot Our Predictions
model.plot(prediction)

# Visualize Each Component [Trends,Weekly]
model.plot_components(prediction)

rmse = np.sqrt(mean_squared_error(test_df.Confirmed[-24:], prediction.yhat[-24:]))
mae = mean_absolute_error(test_df.Confirmed[-24:], prediction.yhat[-24:])
r2 = r2_score(test_df.Confirmed[-24:], prediction.yhat[-24:])
example_dict = {}
example_dict['Prophet'] = [rmse, mae, r2]
test_df['Confirmed'].plot(legend=True,label='ORIGINAL',figsize=(12,5));
prediction['yhat'].plot(legend=True,label='PREDICTION'); 
pickle_out = open("prophet_model_scores_US.p","wb")
pickle.dump(example_dict, pickle_out)
pickle_out.close()
pickle_in = open("prophet_model_scores_US.p","rb")
example_dict = pickle.load(pickle_in)
print(f"RMSE: {rmse}")
print(f"MAE: {mae}")
print(f"R2 Score: {r2}")

pickle_in = open("prophet_model_scores_US.p","rb")
prophet_dict = pickle.load(pickle_in)
print(prophet_dict)

"""#**Holt winter**"""

def get_data(data):
    dt_data = data.set_index('Date').drop('Confirmed_diff', axis=1)
    dt_data.dropna(axis=0)
    
    #dt_data.to_csv('../data/arima_df.csv')
    
    return dt_data

holt_data=get_data(country_df)
holt_data.reset_index(inplace=True)
holt_data.tail()

def holt(data,model_name):
  train_data=data[:-24]
  test_data =data[-24:]
  train_data.drop(columns='Date',inplace=True)
  test_data.drop(columns='Date',inplace=True)
  holt_data['Double ES'] = ExponentialSmoothing(holt_data['Confirmed'].astype(float),trend='add').fit().fittedvalues
  #holt_data[['Confirmed','Triple ES']].plot(figsize=(12,5))
  fitted_model = ExponentialSmoothing(train_data['Confirmed'].astype(float),trend='add').fit()
  test_predictions= fitted_model.forecast(24).rename(f'{model_name} Forecast')
  train_data['Confirmed'].plot(figsize=(12,5),legend=True,label='TRAIN')
  test_data['Confirmed'].plot(legend=True,label='TEST',figsize=(12,5));
  test_predictions.plot(legend=True,label='PREDICTION');  
  get_scores_holt(test_data['Confirmed'],test_predictions,model_name)

def get_scores_holt(test_data,predictions,model_name):
  model_name_dict = {}
  rmse = np.sqrt(mean_squared_error(test_data,predictions))
  mae = mean_absolute_error(test_data,predictions)
  r2 = r2_score(test_data,predictions)
  model_name_dict[f'{model_name}'] = [rmse, mae, r2]
  pickle_out = open(f'{model_name}_model_scores_US.p',"wb")
  pickle.dump(model_name_dict, pickle_out)
  pickle_out.close()
  pickle_in = open(f'{model_name}_model_scores_US.p',"rb")
  model_name_dict = pickle.load(pickle_in)
  print(model_name_dict)
  print(f"RMSE: {rmse}")
  print(f"MAE: {mae}")
  print(f"R2 Score: {r2}")

holt(holt_data,'Holt')

pickle_in = open("Holt_model_scores_US.p","rb")
holtwinter_dict = pickle.load(pickle_in)
print(holtwinter_dict)

"""#**Create Results Dataframe**"""

def create_results_df():
    results_dict = pickle.load(open("model_scores_US.p", "rb"))

    results_dict.update(pickle.load(open("arima_model_scores_US.p", "rb")))
    
    results_dict.update(pickle.load(open("sarimax_model_scores_US.p", "rb")))

    results_dict.update(pickle.load(open("prophet_model_scores_US.p", "rb")))

    results_dict.update(pickle.load(open("Holt_model_scores_US.p", "rb")))

    restults_df = pd.DataFrame.from_dict(results_dict, orient='index', 
                                        columns=['RMSE', 'MAE','R2'])
    
    restults_df = restults_df.sort_values(by='RMSE', ascending=False).reset_index()
    
    return restults_df
    #create_results_df.to_csv('confirmed_index_df.csv')

results = create_results_df()
results

results.to_csv('confirmed_US_index.csv')

"""**Plot Results**"""

def plot_results(results_df):
    fig, ax = plt.subplots(figsize=(12, 5))
    sns.lineplot(np.arange(len(results_df)), 'RMSE', data=results_df, ax=ax, 
                 label='RMSE', color='mediumblue')
    sns.lineplot(np.arange(len(results_df)), 'MAE', data=results_df, ax=ax, 
                 label='MAE', color='Cyan')
    sns.lineplot(np.arange(len(results_df)), 'R2', data=results_df, ax=ax, 
                 label='R2', color='Green')
    
    plt.xticks(np.arange(len(results_df)),rotation=45)
    ax.set_xticklabels(results_df['index'])
    ax.set(xlabel = "Model",
           ylabel = "Scores",
           title = "Model Error Comparison")
    sns.despine()
#plt.savefig(f'/content/{model_name}_usforecast.png')

plot_results(results)

America_average_country_confirmed_cases= 89193.08064516129
gboost = 34463.973146
percentage_off = round(gboost/America_average_country_confirmed_cases*100, 2)

print(f"With XGBoost, prediction is within {percentage_off}% of the actual.")

"""#**Best forcasting module  in India confirmed cases in globle world**"""

#Defining function for country confirmed cases
def country_cases(data):
    country_data = data.copy()
    country_data.Date = country_data.Date.apply(lambda x: str(x)[:-3])
    country_data = country_data.groupby('Date')['Confirmed'].sum().reset_index()
    country_data.Date = pd.to_datetime(country_data.Date)
    return country_data

country_df = country_cases(India_confirmed)
country_df.tail()

def confirmed_cases_per_day():
    fig, ax = plt.subplots(figsize=(7,4))
    plt.hist(country_df.Confirmed, color='mediumblue')
    
    ax.set(xlabel = "confirmed Per day",
           ylabel = "Cases",
           title = "India Distrobution of confirmred cases Per Day")
    
confirmed_cases_per_day()

# Average country confirmed cases

# Overall
avg_country_cases = country_df.Confirmed.mean()
print(f"Overall average India country confirmed cases: {avg_country_cases}cases")

"""Determining Stationarity"""

def time_plot(data, x_col, y_col, title):
    fig, ax = plt.subplots(figsize=(15,5))
    sns.lineplot(x_col, y_col, data=data, ax=ax, color='mediumblue', label='Total cases')
    
    second = data.groupby(data.Date.dt.year)[y_col].mean().reset_index()
    second.Date = pd.to_datetime(second.Date, format='%Y')
    sns.lineplot((second.Date + datetime.timedelta(365/12)), y_col, data=second, ax=ax, color='red', label='Mean cases')   
    
    ax.set(xlabel = "Date",
           ylabel = "confirmed",
           title = title)
    
    sns.despine()

time_plot(country_df, 'Date', 'Confirmed','country confirmed cases Before Diff Transformation')

def get_diff(data):
    data['Confirmed_diff'] = data.Confirmed.diff()
    data = data.dropna()
    
    return data

stationary_df = get_diff(country_df)

time_plot(stationary_df, 'Date', 'Confirmed_diff','India country cases After Diff Transformation')

def plots(data, lags=None):
    
    # Convert dataframe to datetime index
    dt_data = data.set_index('Date').drop('Confirmed', axis=1)
    dt_data.dropna(axis=0)
    
    layout = (1, 3)
    raw  = plt.subplot2grid(layout, (0, 0))
    acf  = plt.subplot2grid(layout, (0, 1))
    pacf = plt.subplot2grid(layout, (0, 2))
    
    dt_data.plot(ax=raw, figsize=(12, 5), color='mediumblue')
    smt.graphics.plot_acf(dt_data, lags=lags, ax=acf, color='mediumblue')
    smt.graphics.plot_pacf(dt_data, lags=lags, ax=pacf, color='mediumblue')
    sns.despine()
    plt.tight_layout()

plots(stationary_df, lags=24);

"""Preparing Dataset Modeling"""

#create dataframe for transformation from time series to supervised
def generate_supervised(data):
    supervised_df = data.copy()
    
    #create column for each lag
    for i in range(1,24):
        col_name = 'lag_' + str(i)
        supervised_df[col_name] = supervised_df['Confirmed_diff'].shift(i)
    
    #drop null values
    supervised_df = supervised_df.dropna().reset_index(drop=True)
    
   # supervised_df.to_csv('../data/model_df.csv', index=False)
    
    return supervised_df

model_df = generate_supervised(stationary_df)
model_df.head()

"""**ARIMA Modeling**"""

def generate_arima_data(data):
    dt_data = data.set_index('Date').drop('Confirmed', axis=1)
    dt_data.dropna(axis=0)
    
    #dt_data.to_csv('../data/arima_df.csv')
    
    return dt_data

datetime_df = generate_arima_data(stationary_df)
datetime_df.tail()

"""Train Test Split"""

def tts(data):
    data = data.drop(['Date','Confirmed'],axis=1)
    train, test = data[:-24].values, data[-24:].values
    
    return train, test

train, test = tts(model_df)

train.shape

test.shape

def scale_data(train_set, test_set):
    #apply Min Max Scaler
    scaler = MinMaxScaler(feature_range=(-1, 1))
    scaler = scaler.fit(train_set)
    
    # reshape training set
    train_set = train_set.reshape(train_set.shape[0], train_set.shape[1])
    train_set_scaled = scaler.transform(train_set)
    
    # reshape test set
    test_set = test_set.reshape(test_set.shape[0], test_set.shape[1])
    test_set_scaled = scaler.transform(test_set)
    
    X_train, y_train = train_set_scaled[:, 1:], train_set_scaled[:, 0:1].ravel()
    X_test, y_test = test_set_scaled[:, 1:], test_set_scaled[:, 0:1].ravel()
    
    return X_train, y_train, X_test, y_test, scaler

X_train, y_train, X_test, y_test, scaler_object = scale_data(train, test)

"""Modeling Functions"""

def undo_scaling(y_pred, x_test, scaler_obj, lstm=False):  
    #reshape y_pred
    y_pred = y_pred.reshape(y_pred.shape[0], 1, 1)
    
    if not lstm:
        x_test = x_test.reshape(x_test.shape[0], 1, x_test.shape[1])
    
    #rebuild test set for inverse transform
    pred_test_set = []
    for index in range(0,len(y_pred)):
        pred_test_set.append(np.concatenate([y_pred[index],x_test[index]],axis=1))
        
    #reshape pred_test_set
    pred_test_set = np.array(pred_test_set)
    pred_test_set = pred_test_set.reshape(pred_test_set.shape[0], pred_test_set.shape[2])
    
    #inverse transform
    pred_test_set_inverted = scaler_obj.inverse_transform(pred_test_set)
    
    return pred_test_set_inverted

def load_original_df():
    #load in original dataframe without scaling applied
    original_df = country_df
    original_df.Date = original_df.Date.apply(lambda x: str(x)[:-3])
    original_df = original_df.groupby('Date')['Confirmed'].sum().reset_index()
    original_df.Date = pd.to_datetime(original_df.Date)
    #df['Timestamp'] = pd.to_datetime(df['Year'],format='%Y') 
    return original_df

def predict_df(unscaled_predictions, original_df):
    #create dataframe that shows the predicted cases
    result_list = []
    cases_dates = list(original_df[-26:].Date)
    act_confirmed = list(original_df[-26:].Confirmed)

    for index in range(0,len(unscaled_predictions)):
        result_dict = {}
        result_dict['pred_value'] = int(unscaled_predictions[index][0] + act_confirmed[index])
        result_dict['Date'] = cases_dates[index+1]
        result_list.append(result_dict)
        
    df_result = pd.DataFrame(result_list)
        
    return df_result

model_scores = {}

def get_scores(unscaled_df, original_df, model_name):
    rmse = np.sqrt(mean_squared_error(original_df.Confirmed[-24:], unscaled_df.pred_value[-24:]))
    mae = mean_absolute_error(original_df.Confirmed[-24:], unscaled_df.pred_value[-24:])
    r2 = r2_score(original_df.Confirmed[-24:], unscaled_df.pred_value[-24:])
    model_scores[model_name] = [rmse, mae, r2]

    print(f"RMSE: {rmse}")
    print(f"MAE: {mae}")
    print(f"R2 Score: {r2}")

def plot_results(results, original_df, model_name):

    fig, ax = plt.subplots(figsize=(15,5))
    sns.lineplot(original_df.Date, original_df.Confirmed, data=original_df, ax=ax,label='Original', color='mediumblue')
    sns.lineplot(results.Date, results.pred_value, data=results, ax=ax,label='Predicted', color='Red')
    
    ax.set(xlabel = "Date",
           ylabel = "Confirmed",
           title = f"{model_name} corona Forecasting Prediction")
    
    ax.legend()
    
    sns.despine()
    
    plt.savefig(f'/content/{model_name}_forecast.png')

def run_model(train_data, test_data, model, model_name):
    
    X_train, y_train, X_test, y_test, scaler_object = scale_data(train_data, test_data)
    
    mod = model
    mod.fit(X_train, y_train)
    predictions = mod.predict(X_test)
    
    # Undo scaling to compare predictions against original data
    original_df = load_original_df()
    unscaled = undo_scaling(predictions, X_test, scaler_object)
    unscaled_df = predict_df(unscaled, original_df)
      
    get_scores(unscaled_df, original_df, model_name)
    
    plot_results(unscaled_df, original_df, model_name)

"""**Linear Regression**"""

run_model(train, test, LinearRegression(), 'LinearRegression')

"""**Random Forest Regressor**"""

run_model(train, test, RandomForestRegressor(n_estimators=100, max_depth=20),'RandomForest')

"""**XGBoost**"""

run_model(train, test, XGBRegressor( n_estimators=100, learning_rate=0.2, objective='reg:squarederror'), 'XGBoost')

"""**LSTM**"""

def lstm_model(train_data, test_data):
    
    X_train, y_train, X_test, y_test, scaler_object = scale_data(train_data, test_data)
    
    X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])
    X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])
   
    model = Sequential()
    model.add(LSTM(4, batch_input_shape=(1, X_train.shape[1], X_train.shape[2]), 
                   stateful=True))
    model.add(Dense(1))
    model.add(Dense(1))
    model.compile(loss='mean_squared_error', optimizer='adam')
    model.fit(X_train, y_train, epochs=200, batch_size=1, verbose=1, 
              shuffle=False)
    predictions = model.predict(X_test,batch_size=1)
    
    original_df = country_df
    unscaled = undo_scaling(predictions, X_test, scaler_object, lstm=True)
    unscaled_df = predict_df(unscaled, original_df)
    
    get_scores(unscaled_df, original_df, 'LSTM')
    
    plot_results(unscaled_df, original_df, 'LSTM')

lstm_model(train, test)

pickle.dump(model_scores, open( "model_scores_IND.p", "wb" ) )

"""**Arima module**

ARIMA Model
"""

ts_data = datetime_df

ts_data.index = pd.to_datetime(ts_data.index)   #Prasanta - Need to understand what we are doing over here
ts_data.reset_index(inplace=True)
ts_data.tail()

train_data_arima = ts_data.iloc[:-24]   #Prasanta - Need to understand what exactly we are doing here. We have done it before other way!!!
test_data_arima=ts_data.iloc[-24:]       #Why we are not using the function that we already defined for train-test split tts()

#Prasanta - we may not need to define this function. With auto-arima we should be able to figure out p, d, q values 
#which can be used for defining model-arima() function
def model_arima(data):
  stepwise_fit = auto_arima(data['Confirmed_diff'], start_p=0, start_q=0,     #Prasanta - Would it not be ts_data[]???
                          max_p=6, max_q=6, m=7,
                          seasonal=False,
                          d=None, trace=True,
                          error_action='ignore',   # we don't want to know if an order does not work
                          suppress_warnings=True,  # we don't want convergence warnings
                          stepwise=True)        # set to stepwise
  stepwise_fit.plot_diagnostics(figsize=(10, 8));    #Prasanta - why semi colon here?
  stepwise_fit.summary()

model_arima(ts_data)

"""Note : Choose the lowest AIC value order

**Prasanta - Can we summarize the observations from the graphical plots**
"""

#Function for forecasting by ARIMA Model
#Prasanta - Should it not be arima_model() function similar to lstm_model()???

def arima_predictions(train,test,p,d,q):
  order=(p,d,q)
  model_arima = ARIMA(train['Confirmed_diff'].astype(float),order=order)
  results_arima = model_arima.fit()
  #  predictions
  start=len(train)
  end=len(train)+len(test)-1
  predictions_arima = results_arima.predict(start=start, end=end, dynamic=False, typ='levels').rename('ARIMA(0,2,1) Predictions')
  get_scores_arima(test,predictions_arima)         #Prasanta - How do we arrive at ARIMA(0,2,1) which needs to be shown before
  plot_results(train,test, predictions_arima, 'Arima_forecast')   #Prasanta - Please check the 3 parameters to be passed in both get_scores and plot_results
  #ts_data.iloc[:,1].plot(legend=True,figsize=(12,6));            #Seems to be something gone wrong in above 2 line of codes
  #predictions_arima.plot(legend=True,figsize=(12,6));            #as both functions must either be re-used or defined (if at all needed)
  #test.iloc[:,1].plot(legend=True,figsize=(12,6));               #prior to arima_predictions() 
  
  #print(type(predictions_arima))
  #return predictions_arima

def get_scores_arima(expected,predicted):  #Prasanta - Can we not re-use the same get_scores function in ARIMA?
    
    model_scores = {}
    
    rmse = np.sqrt(mean_squared_error(expected.iloc[:,1], predicted))
    mae = mean_absolute_error(expected.iloc[:,1],predicted)
    r2 = r2_score(expected.iloc[:,1], predicted)
    
    model_scores['ARIMA'] = [rmse, mae, r2]
    
    print(f"RMSE: {rmse}")
    print(f"MAE: {mae}")
    print(f"R2 Score: {r2}")
    
    pickle.dump(model_scores, open( "arima_model_scores_IND.p", "wb" ))

def plot_results(train,test,predictions,model_name):   #Prasanta - Can we not re-use the same get_scores function in ARIMA?


    fig, ax = plt.subplots(figsize=(15,5))
    sns.lineplot(train.Date, train.Confirmed_diff, data=train, ax=ax,label='Original train', color='mediumblue')
    sns.lineplot(test.Date, test.Confirmed_diff, data=test, ax=ax,label='Original test', color='mediumblue')
    sns.lineplot(test.Date, predictions, data=test, ax=ax,label='predictions', color='Red')
    
    ax.set(xlabel = "Date",
           ylabel = "Confirmed",
           title = f"{model_name} corona Forecasting Prediction")
    
    ax.legend()
    
    sns.despine()
    plt.savefig(f'/content/{model_name}_forecast.png')

arima_predictions(train_data_arima,test_data_arima,0,1,1)

def plot_results(train,test,predictions,model_name):    #Prasanta - Is this defined specific to Prophet model?
                                                        #It seems to be duplicated. Please check

    fig, ax = plt.subplots(figsize=(15,5))
    sns.lineplot(train.Date, train.Confirmed_diff, data=train, ax=ax,label='Original train', color='mediumblue')
    sns.lineplot(test.Date, test.Confirmed_diff, data=test, ax=ax,label='Original test', color='mediumblue')
    sns.lineplot(test.Date, predictions, data=test, ax=ax,label='predictions', color='Red')
    
    ax.set(xlabel = "Date",
           ylabel = "Confirmed",
           title = f"{model_name} corona Forecasting Prediction")
    
    ax.legend()
    
    sns.despine()
    plt.savefig(f'/content/{model_name}_forecast.png')

"""SARIMAX Modeling"""

def get_scores(data):
    
    model_scores = {}
    
    rmse = np.sqrt(mean_squared_error(data.Confirmed_diff[-24:], data.forecast[-24:]))
    mae = mean_absolute_error(data.Confirmed_diff[-24:], data.forecast[-24:])
    r2 = r2_score(data.Confirmed_diff[-24:], data.forecast[-24:])
    model_scores['SARIMAX'] = [rmse, mae, r2]
    
    print(f"RMSE: {rmse}")
    print(f"MAE: {mae}")
    print(f"R2 Score: {r2}")
    
    pickle.dump(model_scores, open( "sarimax_model_scores_IND.p", "wb" ))

def sarimax_model(data):
    
    # Model
    sar = sm.tsa.statespace.SARIMAX(ts_data.Confirmed_diff, order=(12,0,0), seasonal_order=(0,1,0,12), trend='c').fit()

    # Predictions
    start, end, dynamic = 90, 122, 7
    data['forecast'] = sar.predict(start=start, end=end, dynamic=dynamic) 
    pred_df = data.forecast[start+dynamic:end]
    
    data[['Confirmed_diff', 'forecast']].plot(color=['mediumblue', 'Red'])
    
    get_scores(data)

    return sar, data, pred_df

sar, ts_data, predictions = sarimax_model(ts_data)

sar.plot_diagnostics(figsize=(10, 8));

"""Plot Results"""

def predict_df(prediction_df):
    
    #load in original dataframe without scaling applied
    original_df = country_df
   # original_df.Date = original_df.Date.apply(lambda x: str(x)[:-3])
   # original_df = original_df.groupby('Date')['Confirmed'].sum().reset_index()
   # original_df.Date = pd.to_datetime(original_df.Date)
    
    #create dataframe that shows the predicted sales
    result_list = []
    conf_dates = list(original_df[-26:].Date)
    act_conf = list(original_df[-26:].Confirmed)
    
    for index in range(0,len(prediction_df)):
        result_dict = {}
        result_dict['pred_value'] = int(prediction_df[index] + act_conf[index])
        result_dict['Date'] = conf_dates[index+1]
        result_list.append(result_dict)
        
    df_result = pd.DataFrame(result_list)
    
    return df_result, original_df

def plot_results(results, original_df, model_name):

    fig, ax = plt.subplots(figsize=(15,5))
    sns.lineplot(original_df.Date, original_df.Confirmed, data=original_df, ax=ax,label='Original', color='mediumblue')
    sns.lineplot(results.Date, results.pred_value, data=results, ax=ax,label='Predicted', color='Red')
    
    ax.set(xlabel = "Date",
           ylabel = "Confirmed",
           title = f"{model_name} corona Forecasting Prediction")
    
    ax.legend()
    
    sns.despine()
     # plt.savefig(f'/content/{model_name}_forecast.png')

#prediction_df, original_df = predict_df(predictions)

#plot_results(prediction_df, original_df, 'arima')

"""**Prophet module**"""

def get_data(data):
    dt_data = data.set_index('Date').drop('Confirmed_diff', axis=1)
    dt_data.dropna(axis=0)
    
    #dt_data.to_csv('../data/arima_df.csv')
    
    return dt_data

df = get_data(country_df)
df.reset_index(inplace=True)
train_df= df[:-24]
test_df= df[-24:]
train_confirmed= pd.DataFrame()
train_confirmed['ds'] = train_df['Date']
train_confirmed['y']= train_df['Confirmed']
model = Prophet()
model.fit(train_confirmed)
future_dates = model.make_future_dataframe(periods =24)
prediction = model.predict(future_dates)

# Plot Our Prediction
model.plot(prediction)

# Visualize Each Component [Trends,Weekly]
model.plot_components(prediction)

rmse = np.sqrt(mean_squared_error(test_df.Confirmed[-24:], prediction.yhat[-24:]))
mae = mean_absolute_error(test_df.Confirmed[-24:], prediction.yhat[-24:])
r2 = r2_score(test_df.Confirmed[-24:], prediction.yhat[-24:])
example_dict = {}
example_dict['Prophet'] = [rmse, mae, r2]
test_df['Confirmed'].plot(legend=True,label='ORIGINAL',figsize=(12,5));
prediction['yhat'].plot(legend=True,label='PREDICTION'); 
pickle_out = open("prophet_model_scores_IND.p","wb")
pickle.dump(example_dict, pickle_out)
pickle_out.close()
pickle_in = open("prophet_model_scores_IND.p","rb")
example_dict = pickle.load(pickle_in)
print(f"RMSE: {rmse}")
print(f"MAE: {mae}")
print(f"R2 Score: {r2}")

predictons, =plt.plot(prediction.yhat[-24:], label='Predictions')
actual, =plt.plot(test_df.Confirmed[-24:], label='Actual')
plt.xlabel('Number of weeks')
plt.ylabel('Cancellations')
plt.title("Predicted vs. Actual Cancellations Per Week")
plt.legend(loc = 'upper center')
plt.show()

"""**Holt winter**"""

def get_data(data):
    dt_data = data.set_index('Date').drop('Confirmed_diff', axis=1)
    dt_data.dropna(axis=0)
    
    #dt_data.to_csv('../data/arima_df.csv')
    
    return dt_data

holt_data= get_data(country_df)
holt_data.reset_index(inplace= True)

def holt(data,model_name):
  train_data=data[:-24]
  test_data =data[-24:]
  train_data.drop(columns='Date',inplace=True)
  test_data.drop(columns='Date',inplace=True)
  holt_data['Double ES'] = ExponentialSmoothing(holt_data['Confirmed'].astype(float),trend='add').fit().fittedvalues
  #holt_data[['Confirmed','Triple ES']].plot(figsize=(12,5))
  fitted_model = ExponentialSmoothing(train_data['Confirmed'].astype(float),trend='add').fit()
  test_predictions= fitted_model.forecast(24).rename(f'{model_name} Forecast')
  train_data['Confirmed'].plot(figsize=(12,5),legend=True,label='TRAIN')
  test_data['Confirmed'].plot(legend=True,label='TEST',figsize=(12,5));
  test_predictions.plot(legend=True,label='PREDICTION');  
  get_scores_holt(test_data['Confirmed'],test_predictions,model_name)

def get_scores_holt(test_data,predictions,model_name):
  model_name_dict = {}
  rmse = np.sqrt(mean_squared_error(test_data,predictions))
  mae = mean_absolute_error(test_data,predictions)
  r2 = r2_score(test_data,predictions)
  model_name_dict[f'{model_name}'] = [rmse, mae, r2]
  pickle_out = open(f'{model_name}_model_scores_IND.p',"wb")
  pickle.dump(model_name_dict, pickle_out)
  pickle_out.close()
  pickle_in = open(f'{model_name}_model_scores_IND.p',"rb")
  model_name_dict = pickle.load(pickle_in)
  print(model_name_dict)
  print(f"RMSE: {rmse}")
  print(f"MAE: {mae}")
  print(f"R2 Score: {r2}")

holt(holt_data,'Holt')

pickle_in = open("Holt_model_scores_IND.p","rb")
holtwinter_dict = pickle.load(pickle_in)

print(holtwinter_dict)

"""##**Create Results Dataframe**"""

def create_results_df():
    results_dict = pickle.load(open("model_scores_IND.p", "rb"))

    results_dict.update(pickle.load(open("arima_model_scores_IND.p", "rb")))
    
    results_dict.update(pickle.load(open("sarimax_model_scores_IND.p", "rb")))

    results_dict.update(pickle.load(open("prophet_model_scores_IND.p", "rb")))

    results_dict.update(pickle.load(open("Holt_model_scores_IND.p", "rb")))

    restults_df = pd.DataFrame.from_dict(results_dict, orient='index', 
                                        columns=['RMSE', 'MAE','R2'])
    
    restults_df = restults_df.sort_values(by='RMSE', ascending=False).reset_index()
    
    return restults_df
    #create_results_df.to_csv('confirmed_index_df.csv')

results = create_results_df()
results

results.to_csv('confirmed_Ind_index.csv')

"""**Plot Results**"""

def plot_results(results_df):
    fig, ax = plt.subplots(figsize=(12, 5))
    sns.lineplot(np.arange(len(results_df)), 'RMSE', data=results_df, ax=ax, 
                 label='RMSE', color='mediumblue')
    sns.lineplot(np.arange(len(results_df)), 'MAE', data=results_df, ax=ax, 
                 label='MAE', color='Cyan')
    sns.lineplot(np.arange(len(results_df)), 'R2', data=results_df, ax=ax, 
                 label='R2', color='Green')
    
    plt.xticks(np.arange(len(results_df)),rotation=45)
    ax.set_xticklabels(results_df['index'])
    ax.set(xlabel = "Model",
           ylabel = "Scores",
           title = "Model Error Comparison")
    sns.despine()
#plt.savefig(f'/content/{model_name}_usforecast.png')

plot_results(results)

average_country_confirmed_cases= 89193.08064516129
gboost = 34463.973146
percentage_off = round(gboost/average_country_confirmed_cases*100, 2)

print(f"With XGBoost, prediction is within {percentage_off}% of the actual.")

